library(tidyverse)
library(wooldridge)
library(nycflights13)
library(babynames)
install.packages("nycflights13")
library(babynames)
library("babynames)
install.packages("babynames")
install.packages("maps")
## load packages -----------------
library(rvest)
library(stringr)
library(maps)
# parse URL
parsed_url <- read_html("https://en.wikipedia.org/wiki/Berlin")
# extract data
parsed_nodes <- html_nodes(parsed_url, xpath = "//div[contains(@class, 'div-col columns column-width')]//li")
cities <- html_text(parsed_nodes)
cities
# subset data
cities <- str_subset(cities, ":", negate = TRUE)
# tidy data
cities <- str_replace(cities, "\\[\\d+\\]", "")
cities <- html_text(parsed_nodes)
cities
# subset data
cities <- str_subset(cities, ":", negate = TRUE)
cities
# extract data
parsed_nodes <- html_nodes(parsed_url, xpath = "//div[contains(@class, 'div-col columns column-width')]//li")
cities <- html_text(parsed_nodes)
cities
# extract data
parsed_nodes <- html_nodes(parsed_url, xpath = "//div[contains(@class, 'div-col columns column-width')]//li")
cities <- html_text(parsed_nodes)
cities
# subset data
cities <- str_subset(cities, ":", negate = TRUE)
cities
cities
# tidy data
cities <- str_replace(cities, "\\[\\d+\\]", "")
cities[1:10]
# tidy data
cities <- str_replace(cities, "\\[\\d+\\]", "") # remove the footnote symbols
cities[1:10]
cities
# extract variables
year <- str_extract(cities, "\\d{4}")
city <- str_extract(cities, "[[:alpha:] ]+") %>% str_trim
country <- str_extract(cities, "[[:alpha:] ]+$") %>% str_trim
year[1:10]
city[1:10]
country[1:10]
# make data frame
cities_df <- data.frame(year, city, country)
cities_df
head(cities_df)
library(nominatim)
# geocode observations with nominatim package
devtools::install_github("hrbrmstr/nominatim") # not on CRAN, so install from GitHub
library(nominatim)
cities_to_geocode <- paste0(cities_df$city, ", ", cities_df$country)
cities_to_geocode
# get free API key at browseURL("https://developer.mapquest.com/")
load("/Users/s.munzert/rkeys.RDa") # load key from local file; you have to create your own file or paste your key into an object named 'openstreetmap'
# get free API key at browseURL("https://developer.mapquest.com/")
load("/Users/simonmunzert/rkeys.RDa") # load key from local file; you have to create your own file or paste your key into an object named 'openstreetmap'
lats_longs <- osm_geocode(cities_to_geocode, key = openstreetmap)
lats_longs[c("lat", "lon")]
# map observations
map_world <- borders("world", colour = "gray50", fill = "white")
ggplot() + map_world + geom_point(aes(x = lats_longs$lon, y = lats_longs$lat), color = "red", size = 1) + theme_void()
save(lat_longs, file = "cities_lat_longs.RData")
save(lats_longs, file = "cities_lat_longs.RData")
library(stringr)
## string basics -----------------
# to create strings, both single and double quotes work
string1 <- 'This is a string'
string2 <- 'If I want to include a "quote" inside a string, I use single quotes'
# to include a literal single or double quote in a string you can use \ to escape it:
double_quote <- "\"" # or '"'
single_quote <- '\'' # or "'"
# many special characters around, see
?"'"
# example
raw.data <- "555-1239Moe Szyslak(636) 555-0113Burns, C. Montgomery555-6542Rev. Timothy Lovejoy555 8904Ned Flanders636-555-3226Simpson, Homer5553642Dr. Julius Hibbert"
name <- unlist(str_extract_all(raw.data, "[[:alpha:]., ]{2,}"))
name
phone <- unlist(str_extract_all(raw.data, "\\(?(\\d{3})?\\)?(-| )?\\d{3}(-| )?\\d{4}"))
phone
data.frame(name = name, phone = phone)
# running example
example.obj <- "1. A small sentence. - 2. Another tiny sentence."
# self match
str_extract(example.obj, "small")
str_extract(example.obj, "banana")
# multiple matches
(out <- str_extract_all(c("text", "manipulation", "basics"), "a"))
# case sensitivity
str_extract(example.obj, "small")
str_extract(example.obj, "SMALL")
str_extract(example.obj, regex("SMALL", ignore_case = TRUE))
# match empty space
str_extract(example.obj, "mall sent")
# match the beginning of a string
str_extract(example.obj, "^1")
str_extract(example.obj, "^2")
# match the end of a string
str_extract(example.obj, "sentence$")
str_extract(example.obj, "sentence.$")
# pipe operator
unlist(str_extract_all(example.obj, "tiny|sentence"))
# wildcard
str_extract(example.obj, "sm.ll")
# character class
str_extract(example.obj, "sm[abc]ll")
# character class: range
str_extract(example.obj, "sm[a-p]ll")
# character class: additional characters
unlist(str_extract_all(example.obj, "[uvw. ]"))
# pre-defined character classes
unlist(str_extract_all(example.obj, "[:punct:]"))
unlist(str_extract_all(example.obj, "[[:punct:]ABC]"))
unlist(str_extract_all(example.obj, "[^[:alnum:]]"))
# for more character classes, see
?base::regex
# additional shortcuts
unlist(str_extract_all(example.obj, "\\w+"))
# word edges
unlist(str_extract_all(example.obj, "e\\b"))
unlist(str_extract_all(example.obj, "e\\B"))
# quantifier
str_extract(example.obj, "s[:alpha:][:alpha:][:alpha:]l")
str_extract(example.obj, "s[:alpha:]{3}l")
str_extract(example.obj, "A.+sentence")
# greedy quantification
str_extract(example.obj, "A.+sentence")
str_extract(example.obj, "A.+?sentence")
# quantifier with pattern sequence
unlist(str_extract_all(example.obj, "(.en){1,5}"))
unlist(str_extract_all(example.obj, ".en{1,5}"))
# meta characters
unlist(str_extract_all(example.obj, "\\."))
unlist(str_extract_all(example.obj, fixed(".")))
# meta characters in character classes
unlist(str_extract_all(example.obj, "[1-2]"))
unlist(str_extract_all(example.obj, "[12-]"))
# backreferencing
str_extract(example.obj, "([:alpha:]).+?\\1")
str_extract(example.obj, "(\\b[a-z]+\\b).+?\\1")
# do you think you can master regular expressions now?
browseURL("http://stackoverflow.com/questions/201323/using-a-regular-expression-to-validate-an-email-address/201378#201378") # think again
# stringr is built on top of the stringi package.
# stringr is convenient because it exposes a minimal set of functions, which have been carefully picked to handle the most common string manipulation functions.
# stringi is designed to be comprehensive. It contains almost every function you might ever need: stringi has 234 functions (compare that to stringr's 42)
# packages work very similarly; translating knowledge is easy (try stri_ instead of str_)
library(stringi)
?stri_count_words
example.obj
stri_count_words(example.obj)
stri_stats_latex(example.obj)
stri_stats_general(example.obj)
stri_escape_unicode("\u00b5")
stri_unescape_unicode("\u00b5")
stri_rand_lipsum(3)
stri_rand_shuffle("hello")
stri_rand_strings(100, 10, pattern = "[berlin]")
stri_unescape_unicode("\U0001f600")
stri_unescape_unicode("\u0001f600")
stri_escape_unicode("\U0001f600")
library(utf8)
utf8_print(intToUtf8(0x1f600 + 0:79)) # truncates to line width
stri_rand_strings(100, 10, pattern = "[berlin]")
## load packages -----------------
library(stringr)
## string manipulation ----------
example.obj <- "1. A small sentence. - 2. Another tiny sentence."
example.obj
# locate
str_locate(example.obj, "tiny")
# substring extraction
str_sub(example.obj, start = 35, end = 38)
# replacement
str_sub(example.obj, 35, 38) <- "huge"
str_replace(example.obj, pattern = "huge", replacement = "giant")
# splitting
str_split(example.obj, "-") %>% unlist
# manipulate multiple elements; example
(char.vec <- c("this", "and this", "and that"))
# detection
str_detect(char.vec, "this")
# keep strings matching a pattern
str_subset(char.vec, "this") # wrapper around x[str_detect(x, pattern)]
# counting
str_count(char.vec, "this")
str_count(char.vec, "\\w+")
str_length(char.vec)
# duplication
str_dup(char.vec, 3)
# padding and trimming
length.char.vec <- str_length(char.vec)
char.vec <- str_pad(char.vec, width = max(length.char.vec), side = "both", pad = " ")
char.vec
str_trim(char.vec)
# joining
str_c("text", "manipulation", sep = " ")
str_c(char.vec, collapse = "\n") %>% cat
str_c("text", c("manipulation", "basics"), sep = " ")
# approximate matching
agrepl("Donald Trump", "Donald Drumpf", max.distance = list(all = 3))
agrepl("Donald Trump", "Barack Obama", max.distance = list(all = 3))
# load packages
library(stringr)
library(rvest)
# query your locale for individual categories
localeCategories <- c("LC_COLLATE","LC_CTYPE","LC_MONETARY","LC_NUMERIC","LC_TIME")
# sample from the list of available conversions
(encodings <- length(iconvlist()))
sample(iconvlist(), 10)
# an example string
small.frogs <- "SmÃ¥ grodorna, smÃ¥ grodorna Ã¤r lustiga att se."
small.frogs
library(tidyverse)
library(rvest)
library(pdftools)
# devtools::install_github("hrbrmstr/nominatim")
library(nominatim)
## step 1: inspect page
url <- "http://ajps.org/list-of-reviewers/"
browseURL(url)
## step 2: retrieve pdfs
# get page
content <- read_html(url)
# get anchor (<a href=...>) nodes via xpath
anchors <- html_nodes(content, xpath = "//a")
# get value of anchors' href attribute
hrefs <- html_attr(anchors, "href")
# filter links to pdfs
pdfs <- hrefs[ str_detect(basename(hrefs), ".*\\d{4}.*pdf") ]
pdfs
# define names for pdfs on disk
pdf_names <- str_extract(basename(pdfs), "\\d{4}") %>% paste0("reviewers", ., ".pdf")
pdf_names
# download pdfs
dir.create("ajps-reviewers")
for(i in seq_along(pdfs)) {
download.file(pdfs[i], paste0("ajps-reviewers/", pdf_names[i]), mode="wb")
}
## step 3: import pdf
rev_raw <- pdftools::pdf_text("ajps-reviewers/reviewers2015.pdf")
class(rev_raw)
rev_raw[1]
## step 4: tidy data
rev_all <- rev_raw %>% str_split("\\n") %>% unlist
surname <- str_extract(rev_all, "[[:alpha:]-]+")
prename <- str_extract(rev_all, " [.[:alpha:]]+")
rev_df <- data.frame(raw = rev_all, surname = surname, prename = prename, stringsAsFactors = F)
rev_df$institution <- NA
for(i in 1:nrow(rev_df)) {
rev_df$institution[i] <- rev_df$raw[i] %>% str_replace(rev_df$surname[i], "") %>% str_replace(rev_df$prename[i], "") %>% str_trim()
}
rev_df <- rev_df[-c(1,2),]
rev_df <- rev_df[!is.na(rev_df$surname),]
head(rev_df)
View(rev_df)
install.packages("rnaturalearth")
regex <- ".*"
string <- c("1. This is an example string by", "2. Eddie (born 1961 in MÃ¼nchen)", "!Â§%$&/)(}")
regex <- ".*"
string <- c("1. This is an example string by", "2. Eddie (born 1961 in MÃ¼nchen)", "!Â§%$&/)(}")
str_extract_all(string, regex)
string <- c("Look at this fancy example string! I can even do ðŸ˜€ðŸ˜ðŸ˜‚", "2. Eddie (born 1961 in MÃ¼nchen)", "!Â§%$&/)(}")
str_extract_all(string, regex)
string <- c("Look at this fancy example string!", "2. Eddie (born 1961 in MÃ¼nchen)", "!Â§%$&/)(}")
str_extract_all(string, regex)
library(tidyverse)
library(rvest)
library(stringr)
# devtools::install_github("hrbrmstr/nominatim")
library(nominatim)
library(sf)
library(rnaturalearth)
browseURL("http://www.biermap24.de/brauereiliste.php")
# set temporary working directory
tempwd <- ("data/breweriesGermany")
dir.create(tempwd)
# set temporary working directory
tempwd <- ("breweriesGermany")
dir.create(tempwd)
setwd(tempwd)
## step 1: fetch list of cities with breweries
url <- "http://www.biermap24.de/brauereiliste.php"
content <- read_html(url)
anchors <- html_nodes(content, xpath = "//tr/td[2]")
cities <- html_text(anchors)
cities
cities <- str_trim(cities)
cities <- cities[str_detect(cities, "^[[:upper:]]+.")]
cities <- cities[6:length(cities)]
length(cities)
length(unique(cities))
sort(table(cities))
unique_cities <- unique(cities)
pos <- data.frame(lon = NA, lat = NA)
setwd("../")
## step 2: geocode cities
# get free key for mapquest API at browseURL("https://developer.mapquest.com/")
load("/Users/s.munzert/rkeys.RDa") # import API key (or paste it here in openstreetmap object)
pos <- data.frame(lon = NA, lat = NA)
if (!file.exists("geocodes_cities.RData")){
for (i in 1:length(unique_cities)) {
pos[i,] <- try(nominatim::osm_search(unique_cities[i], country_codes = "de", key = openstreetmap) %>% dplyr::select(lon, lat))
}
pos$city <- unique_cities
pos <- filter(pos, !str_detect(lon, "Error"))
pos$lon <- as.numeric(pos$lon)
pos$lat <- as.numeric(pos$lat)
save(pos, file="geocodes_breweriers.RData")
} else {
load("geocodes_breweries.RData")
}
dir()
head(pos)
load("geocodes_breweries.RData")
if (!file.exists("geocodes_breweries.RData")){
for (i in 1:length(unique_cities)) {
pos[i,] <- try(nominatim::osm_search(unique_cities[i], country_codes = "de", key = openstreetmap) %>% dplyr::select(lon, lat))
}
pos$city <- unique_cities
pos <- filter(pos, !str_detect(lon, "Error"))
pos$lon <- as.numeric(pos$lon)
pos$lat <- as.numeric(pos$lat)
save(pos, file="geocodes_breweriers.RData")
} else {
load("geocodes_breweries.RData")
}
head(pos)
## step 3: plot breweries of Germany
pos <- filter(pos, lon >= 6, lon <= 15, lat >= 47, lat <= 55)
worldmap <- rnaturalearth::ne_countries(scale = 'medium', type = 'map_units', returnclass = 'sf')
install.packages("rnaturalearthdata")
## step 3: plot breweries of Germany
pos <- filter(pos, lon >= 6, lon <= 15, lat >= 47, lat <= 55)
worldmap <- rnaturalearth::ne_countries(scale = 'medium', type = 'map_units', returnclass = 'sf')
install.packages("rgeos")
## step 3: plot breweries of Germany
pos <- filter(pos, lon >= 6, lon <= 15, lat >= 47, lat <= 55)
worldmap <- rnaturalearth::ne_countries(scale = 'medium', type = 'map_units', returnclass = 'sf')
germany <- worldmap[worldmap$name == 'Germany',]
ggplot() + geom_sf(data = germany) + theme_bw() + geom_point(aes(lon,lat), data = pos, size = .5, color = "red")
View(mtcars)
# enter your R code here
sum(1, 2)
sum(1, 2)
raw.data <- "555-1239Moe Szyslak(636) 555-0113Burns, C. Montgomery555-6542Rev. Timothy Lovejoy555 8904Ned Flanders636-555-3226Simpson, Homer5553642Dr. Julius Hibbert"
phone <- unlist(str_extract_all(raw.data, "\\(?(\\d{3})?\\)?(-| )?\\d{3}(-| )?\\d{4}"))
library(tidyverse)
library(rvest)
raw.data <- "555-1239Moe Szyslak(636) 555-0113Burns, C. Montgomery555-6542Rev. Timothy Lovejoy555 8904Ned Flanders636-555-3226Simpson, Homer5553642Dr. Julius Hibbert"
phone <- unlist(str_extract_all(raw.data, "\\(?(\\d{3})?\\)?(-| )?\\d{3}(-| )?\\d{4}"))
phone
# diagnosis
str_extract("+test" , "\\+.+")
# diagnosis
str_extract("+test" , "\\+.+")
# positive/negative lookahead/lookbehind assertions
example.obj <- "1. A small sentence. - 2. Another tiny sentence."
# positive/negative lookahead/lookbehind assertions
example.obj <- "1. A small sentence. - 2. Another tiny sentence."
unlist(str_extract_all(example.obj, "(?<=2. ).+")) # positive lookbehind: (?<=...)
unlist(str_extract_all(example.obj, ".+(?=2)")) # positive lookahead (?=...)
# solution
str_extract("+test" , "(?<=\\+).+")
str_extract_all("Hello, my name is Simon" , "[[a-z]., ]")
str_extract_all("Hello, my name is Simon" , "[^[., ]]")
str_extract_all("Hello, my name is Simon" , "[^[., ]]")
str_extract_all("Hello, my name is Simon" , "[^., ]") # equivalent
